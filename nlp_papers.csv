X1;tahun;judul;keterangan;urls;topik_no;topik;abstrak
1;2000;A Statistical Part-of-Speech Tagger;TLDR: Seminal paper demonstrating a powerful HMM-based POS tagger. Many tips and tricks for building such classical systems included.;https://arxiv.org/pdf/cs/0003055.pdf;1; Part-of-speech Tagging;Trigrams’n’Tags (TnT) is an efficient statistical part-of-speech tagger. Contrary to claims found elsewhere in the literature, we argue that a tagger based on Markov models performs at least as well as other current approaches, including the Maximum Entropy framework. A recent comparison has even shown that TnT performs significantly better for the tested corpora. We describe the basic model of TnT, the techniques used for smoothing and for handling unknown words. Furthermore, we present evalua- tions on two corpora. 
2;2003;Feature-rich part-of-speech tagging with a cyclic dependency network;TLDR: Proposes a number of powerful linguistic features for building a (then) SOTA POS-tagging system;https://nlp.stanford.edu/pubs/tagging.pdf;1; Part-of-speech Tagging;We present a new part-of-speech tagger that demonstrates the following ideas: (i) explicit use of both preceding and following tag con- texts via a dependency network representa- tion, (ii) broad use of lexical features, includ- ing jointly conditioning on multiple consecu- tive words, (iii) effective use of priors in con- ditional loglinear models, and (iv) fine-grained modeling of unknown word features. Using these ideas together, the resulting tagger gives a 97.24% accuracy on the Penn Treebank WSJ, an error reduction of 4.4% on the best previous single automatically learned tagging result. 
3;2015;Bidirectional LSTM-CRF Models for Sequence Tagging;TLDR: Proposes an element sequence-tagging model combining neural networks with conditional random fields, achieving SOTA in POS-tagging, NER, and chunking.;https://arxiv.org/pdf/1508.01991.pdf;1; Part-of-speech Tagging;In this paper, we propose a variety of Long Short-Term Memory (LSTM) based mod- els for sequence tagging. These mod- els include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tag- ging data sets. We show that the BI- LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM- CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations. 
4;2003;Accurate unlexicalized parsing;TLDR: Beautiful paper demonstrating that unlexicalized probabilistic context free grammars can exceed the performance of lexicalized PCFGs.;https://people.eecs.berkeley.edu/~klein/papers/unlexicalized-parsing.pdf;2; Parsing;We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36% (LP/LR F1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the- art. This result has potential uses beyond establish- ing a strong lower bound on the maximum possi- ble accuracy of unlexicalized models: an unlexical- ized PCFG is much more compact, easier to repli- cate, and easier to interpret than more complex lex- ical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic com- plexity, and easier to optimize. 
6;2005;Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling;TLDR: Using cool Monte Carlo methods combined with a conditional random field model, this work achieves a huge error reduction in certain information extraction benchmarks.;http://nlp.stanford.edu/~manning/papers/gibbscrf3.pdf;2; Parsing;Most current statistical natural language process- ing models use only local features so as to permit dynamic programming in inference, but this makes them unable to fully account for the long distance structure that is prevalent in language use. We show how to solve this dilemma with Gibbs sam- pling, a simple Monte Carlo method used to per- form approximate inference in factored probabilis- tic models. By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorpo- rate non-local structure while preserving tractable inference. We use this technique to augment an existing CRF-based information extraction system with long-distance dependency models, enforcing label consistency and extraction template consis- tency constraints. This technique results in an error reduction of up to 9% over state-of-the-art systems on two established information extraction tasks. 
7;2015;Bidirectional LSTM-CRF Models for Sequence Tagging;TLDR: Proposes an element sequence-tagging model combining neural networks with conditional random fields, achieving SOTA in POS-tagging, NER, and chunking.;https://arxiv.org/pdf/1508.01991.pdf;3; Named Entity Recognition;In this paper, we propose a variety of Long Short-Term Memory (LSTM) based mod- els for sequence tagging. These mod- els include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tag- ging data sets. We show that the BI- LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM- CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations. 
8;2010;A multi-pass sieve for coreference resolution;TLDR: Proposes a sieve-based approach to coreference resolution that for many years (until deep learning approaches) was SOTA.;https://nlp.stanford.edu/pubs/conllst2011-coref.pdf;3; Named Entity Recognition;This paper details the coreference resolution system submitted by Stanford at the CoNLL- 2011 shared task. Our system is a collection of deterministic coreference resolution mod- els that incorporate lexical, syntactic, seman- tic, and discourse information. All these mod- els use global document-level information by sharing mention attributes, such as gender and number, across mentions in the same cluster. We participated in both the open and closed tracks and submitted results using both pre- dicted and gold mentions. Our system was ranked first in both tracks, with a score of 57.8 in the closed track and 58.3 in the open track. 
9;2015;Entity-Centric Coreference Resolution with Model Stacking;TLDR: This work offers a nifty approach to building coreference chains iteratively using entity-level features.;http://cs.stanford.edu/~kevclark/resources/clark-manning-acl15-entity.pdf;4; Coreference Resolution;Mention pair models that predict whether or not two mentions are coreferent have historically been very effective for coref- erence resolution, but do not make use of entity-level information. However, we show that the scores produced by such models can be aggregated to define pow- erful entity-level features between clusters of mentions. Using these features, we train an entity-centric coreference system that learns an effective policy for building up coreference chains incrementally. The mention pair scores are also used to prune the search space the system works in, al- lowing for efficient training with an exact loss function. We evaluate our system on the English portion of the 2012 CoNLL Shared Task dataset and show that it im- proves over the current state of the art. 
10;2016;Improving Coreference Resolution by Learning Entity-Level Distributed Representations;TLDR: One of the earliest effective approaches to using neural networks for coreference resolution, significantly outperforming the SOTA.;https://cs.stanford.edu/~kevclark/resources/clark-manning-acl16-improving.pdf;4; Coreference Resolution;A long-standing challenge in coreference resolution has been the incorporation of entity-level information – features defined over clusters of mentions instead of men- tion pairs. We present a neural net- work based coreference system that pro- duces high-dimensional vector represen- tations for pairs of coreference clusters. Using these representations, our system learns when combining clusters is de- sirable. We train the system with a learning-to-search algorithm that teaches it which local decisions (cluster merges) will lead to a high-scoring final corefer- ence partition. The system substantially outperforms the current state-of-the-art on the English and Chinese portions of the CoNLL 2012 Shared Task dataset despite using few hand-engineered features. 
11;2012;Baselines and Bigrams: Simple, Good Sentiment and Topic Classification;TLDR: Very elegant paper, illustrating that simple Naive Bayes models with bigram features can outperform more sophisticated methods like support vector machines on tasks such as sentiment analysis.;https://www.aclweb.org/anthology/P12-2018;4; Coreference Resolution;Recent trends suggest that neural- network-inspired word embedding models outperform traditional count-based distri- butional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter op- timizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others. 
12;2013;Recursive deep models for semantic compositionality over a sentiment treebank;TLDR: Introduces the Stanford Sentiment Treebank, a wonderful resource for fine-grained sentiment annotation on sentences. Also introduces the Recursive Neural Tensor Network, a neat linguistically-motivated deep learning architecture.;https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf;5; Sentiment Analysis;Semantic word spaces have been very use- ful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation re- sources and more powerful models of com- position. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment composition- ality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model out- performs all previous methods on several met- rics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases. 
13;2007;Natural Logic for Textual Inference;TLDR: Proposes a rigorous logic-based approach to the problem of textual inference called natural logic. Very cool mathematically-motivated transforms are used to deduce the relationship between phrases.;https://nlp.stanford.edu/pubs/natlog-wtep07.pdf;5; Sentiment Analysis;"This paper presents the first use of a com- putational model of natural logic—a sys- tem of logical inference which operates over natural language—for textual infer- ence. Most current approaches to the PAS- CAL RTE textual inference task achieve ro- bustness by sacrificing semantic precision; while broadly effective, they are easily con- founded by ubiquitous inferences involving monotonicity. At the other extreme, systems which rely on first-order logic and theorem proving are precise, but excessively brittle. This work aims at a middle way. Our system finds a low-cost edit sequence which trans- forms the premise into the hypothesis; learns to classify entailment relations across atomic edits; and composes atomic entailments into a top-level entailment judgment. We pro- vide the first reported results for any system on the FraCaS test suite. We also evaluate on RTE3 data, and show that hybridizing an existing RTE system with our natural logic system yields significant performance gains. "
15;2014;Recursive Neural Networks Can Learn Logical Semantics;TLDR: Demonstrates that deep learning architectures such as neural tensor networks can effectively be applied to natural language inference.;https://arxiv.org/pdf/1406.1827.pdf;6; Natural Logic/Inference;Tree-structured recursive neural networks (TreeRNNs) for sentence meaning have been successful for many applications, but it remains an open question whether the fixed-length representations that they learn can support tasks as demanding as logi- cal deduction. We pursue this question by evaluating whether two such models— plain TreeRNNs and tree-structured neural tensor networks (TreeRNTNs)—can cor- rectly learn to identify logical relation- ships such as entailment and contradiction using these representations. In our first set of experiments, we generate artificial data from a logical grammar and use it to eval- uate the models’ ability to learn to handle basic relational reasoning, recursive struc- tures, and quantification. We then evaluate the models on the more natural SICK chal- lenge data. Both models perform compet- itively on the SICK data and generalize well in all three experiments on simulated data, suggesting that they can learn suit- able representations for logical inference in natural language. 
16;2015;A large annotated corpus for learning natural language inference;TLDR: Introduces the Stanford Natural Language Inference corpus, a wonderful NLI resource larger by two orders of magnitude over previous datasets.;http://nlp.stanford.edu/pubs/snli_paper.pdf;6; Natural Logic/Inference;Understanding entailment and contradic- tion is fundamental to understanding nat- ural language, and inference about entail- ment and contradiction is a valuable test- ing ground for the development of seman- tic representations. However, machine learning research in this area has been dra- matically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by hu- mans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This in- crease in scale allows lexicalized classi- fiers to outperform some sophisticated ex- isting entailment models, and it allows a neural network-based model to perform competitively on natural language infer- ence benchmarks for the first time. 
17;1993;The Mathematics of Statistical Machine Translation;TLDR: Introduces the IBM machine translation models, several seminal models in statistical MT.;https://www.aclweb.org/anthology/J93-2003;6; Natural Logic/Inference;"We describe a series o,ffive statistical models o,f the translation process and give algorithms,for estimating the parameters o,fthese models given a set o,fpairs o,fsentences that are translations o,fone another. We define a concept o,fword-by-word alignment between such pairs o,fsentences. For any given pair of such sentences each o,f our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable o,fthese alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair o,fsentences. We have a great deal o,fdata in French and English from the proceedings o,f the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we,feel that because our algorithms have minimal linguistic content they would work well on other pairs o,flanguages. We also,feel, again because of the minimal linguistic content o,four algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus."
18;2002;BLEU: A Method for Automatic Evaluation of Machine Translation;TLDR: Proposes BLEU, the defacto evaluation technique used for machine translation (even today!);https://www.aclweb.org/anthology/P02-1040.pdf;6; Natural Logic/Inference;Human evaluations of machine translation are extensive but expensive. Human eval- uations can take months to finish and in- volve human labor that can not be reused. We propose a method of automatic ma- chine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evalu- ation, and that has little marginal cost per run. We present this method as an auto- mated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations. 
19;2003;Statistical Phrase-Based Translation;TLDR: Introduces a phrase-based translation model for MT, doing nice analysis that demonstrates why phrase-based models outperform word-based ones.;http://delivery.acm.org/10.1145/1080000/1073462/p48-koehn.pdf?ip=119.2.52.231&id=1073462&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1563344668_dde95cd90bb744213141de24431d7dcc;7; Machine Translation;"We describe a series o,ffive statistical models o,f the translation process and give algorithms,for estimating the parameters o,fthese models given a set o,fpairs o,fsentences that are translations o,fone another. We define a concept o,fword-by-word alignment between such pairs o,fsentences. For any given pair of such sentences each o,f our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable o,fthese alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair o,fsentences. We have a great deal o,fdata in French and English from the proceedings o,f the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we,feel that because our algorithms have minimal linguistic content they would work well on other pairs o,flanguages. We also,feel, again because of the minimal linguistic content o,four algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus"
20;2014;Sequence to Sequence Learning with Neural Networks;TLDR: Introduces the sequence-to-sequence neural network architecture. While only applied to MT in this paper, it has since become one of the cornerstone architectures of modern natural language processing.;https://arxiv.org/pdf/1409.3215.pdf;7; Machine Translation;Deep Neural Networks (DNNs) are powerful models that have achieved excel- lent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT’14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM’s BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the pas- sive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM’s performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier. 
21;2015;Neural Machine Translation by Jointly Learning to Align and Translate;TLDR: Extends previous sequence-to-sequence architectures for MT by using the attention mechanism, a powerful tool for allowing a target word to softly search for important signal from the source sentence.;https://arxiv.org/pdf/1409.0473.pdf;7; Machine Translation;Neural machine translation is a recently proposed approach to machine transla- tion. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neu- ral machine translation often belong to a family of encoder–decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder–decoder architec- ture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition. 
22;2015;Effective approaches to attention-based neural machine translation;TLDR: Introduces two new attention mechanisms for MT, using them to achieve SOTA over existing neural MT systems.;https://arxiv.org/pdf/1508.04025.pdf;7; Machine Translation;An attentional mechanism has lately been used to improve neural machine transla- tion (NMT) by selectively focusing on parts of the source sentence during trans- lation. However, there has been little work exploring useful architectures for attention-based NMT. This paper exam- ines two simple and effective classes of at- tentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional sys- tems that already incorporate known tech- niques such as dropout. Our ensemble model using different attention architec- tures yields a new state-of-the-art result in the WMT’15 English to German transla- tion task with 25.9 BLEU points, an im- provement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker 
23;2016;Neural Machine Translation of Rare Words with Subword Units;TLDR: Introduces byte pair encoding, an effective technique for allowing neural MT systems to handle (more) open-vocabulary translation.;https://arxiv.org/pdf/1508.07909.pdf;7; Machine Translation;Neural machine translation (NMT) mod- els typically operate with a fixed vocabu- lary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this pa- per, we introduce a simpler and more ef- fective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as se- quences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via com- positional translation), and cognates and loanwords (via phonological and morpho- logical transformations). We discuss the suitability of different word segmentation techniques, including simple character n- gram models and a segmentation based on the byte pair encoding compression algo- rithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English_German and English_Russian by up to 1.1 and 1.3 BLEU, respectively 
24;2016;Pointing the Unknown Words;TLDR: Proposes a copy-mechanism for allowing MT systems to more effectively copy words from a source context sequence.;https://www.aclweb.org/anthology/P16-1014;7; Machine Translation;Hidden Markov models (HMMs) are a powerful probabilistic tool for modeling sequential data, and have been applied with success to many text-related tasks, such as part-of-speech tagging, text segmentation and information extraction. In these cases, the observations are usually mod- eled as multinomial distributions over a discrete vocabulary, and the HMM parameters are set to maximize the likelihood of the observations. This paper presents a new Markovian sequence model, closely related to HMMs, that allows ob- servations to be represented as arbitrary overlap- ping features (such as word, capitalization, for- matting, part-of-speech), and defines the condi- tional probability of state sequences given ob- servation sequences. It does this by using the maximum entropy framework to fit a set of expo- nential models that represent the probability of a state given an observation and the previous state. We present positive experimental results on the segmentation of FAQ’s 
25;2016;Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation;TLDR: A wonderful case-study demonstrating what a production-capacity machine translation system (in this case that of Google) looks like.;https://arxiv.org/pdf/1609.08144.pdf;7; Machine Translation;Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference – sometimes prohibitively so in the case of very large data sets and large models. Several authors have also charged that NMT systems lack robustness, particularly when input sentences contain rare words. These issues have hindered NMT’s use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google’s Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using residual connections as well as attention connections from the decoder network to the encoder. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (“wordpieces”) for both input and output. This method provides a good balance between the flexibility of “character”-delimited models and the efficiency of “word”-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. To directly optimize the translation BLEU scores, we consider refining the models by using reinforcement learning, but we found that the improvement in the BLEU scores did not reflect in the human evaluation. On the WMT’14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google’s phrase-based production system. 
27;2014;Semantic Parsing via Paraphrasing;TLDR: Develops a unique paraphrase model for learning appropriate candidate logical forms from question-answer pairs, improving SOTA on existing Q/A datasets.;http://aclweb.org/anthology/P14-1133;7; Machine Translation;A central challenge in semantic parsing is handling the myriad ways in which knowl- edge base predicates can be expressed. Traditionally, semantic parsers are trained primarily from text paired with knowledge base information. Our goal is to exploit the much larger amounts of raw text not tied to any knowledge base. In this pa- per, we turn semantic parsing on its head. Given an input utterance, we first use a simple method to deterministically gener- ate a set of candidate logical forms with a canonical realization in natural language for each. Then, we use a paraphrase model to choose the realization that best para- phrases the input, and output the corre- sponding logical form. We present two simple paraphrase models, an association model and a vector space model, and train them jointly from question-answer pairs. Our system PARASEMPRE improves state- of-the-art accuracies on two recently re- leased question-answering datasets. 
28;2015;Building a Semantic Parser Overnight;TLDR: Neat paper showing that a semantic parser can be built from scratch starting with no training examples!;https://cs.stanford.edu/~pliang/papers/overnight-acl2015.pdf;7; Machine Translation;How do we build a semantic parser in a new domain starting with zero training ex- amples? We introduce a new methodol- ogy for this setting: First, we use a simple grammar to generate logical forms paired with canonical utterances. The logical forms are meant to cover the desired set of compositional operators, and the canon- ical utterances are meant to capture the meaning of the logical forms (although clumsily). We then use crowdsourcing to paraphrase these canonical utterances into natural utterances. The resulting data is used to train the semantic parser. We fur- ther study the role of compositionality in the resulting paraphrases. Finally, we test our methodology on seven domains and show that we can build an adequate se- mantic parser in just a few hours. 
29;2015;Bringing Machine Learning and Computational Semantics Together;TLDR: A nice overview of a computational semantics framework that uses machine learning to effectively learn logical forms for semantic parsing.;http://www.stanford.edu/~cgpotts/manuscripts/liang-potts-semantics.pdf;8; Semantic Parsing;"Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/ dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the oppo- site result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on senti- ment analysis datasets, sometimes providing a new state-of-the-art performance level. "
30;2016;A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task;TLDR: A great wake-up call paper, demonstrating that SOTA performance can be achieved on certain reading comprehension datasets using simple systems with carefully chosen features. Don't forget non-deep learning methods!;https://arxiv.org/pdf/1606.02858.pdf;8; Semantic Parsing;Enabling a computer to understand a document so that it can answer comprehension questions is a central, yet unsolved goal of NLP. A key factor impeding its solution by machine learned systems is the limited availability of human-annotated data. Hermann et al. (2015) seek to solve this problem by creating over a million training examples by pairing CNN and Daily Mail news articles with their summarized bullet points, and show that a neural network can then be trained to give good performance on this task. In this paper, we conduct a thorough examination of this new reading comprehension task. Our primary aim is to understand what depth of language understanding is required to do well on this task. We approach this from one side by doing a careful hand-analysis of a small subset of the problems and from the other by showing that simple, carefully designed systems can obtain accuracies of 73.6% and 76.6% on these two datasets, exceeding current state-of-the-art results by 7–10% and approaching what we believe is the ceiling for performance on this task
31;2017;SQuAD: 100,000+ Questions for Machine Comprehension of Text;TLDR: Introduces the SQUAD dataset, a question-answering corpus that has become one of the defacto benchmarks used today.;https://arxiv.org/pdf/1606.05250.pdf;8; Semantic Parsing;We present the Stanford Question Answer- ing Dataset (SQuAD), a new reading compre- hension dataset consisting of 100,000+ ques- tions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the cor- responding reading passage. We analyze the dataset to understand the types of reason- ing required to answer the questions, lean- ing heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple base- line (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com. 
32;2004;ROUGE: A Package for Automatic Evaluation of Summaries;TLDR: Introduces ROUGE, an evaluation metric for summarization that is used to this day on a variety of sequence transduction tasks.;https://www.aclweb.org/anthology/W04-1013;8; Semantic Parsing;ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It includes measures to auto- matically determine the quality of a summary by comparing it to other (ideal) summaries created by humans. The measures count the number of over- lapping units such as n-gram, word sequences, and word pairs between the computer-generated sum- mary to be evaluated and the ideal summaries cre- ated by humans. This paper introduces four different ROUGE measures: ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S included in the ROUGE summariza- tion evaluation package and their evaluatio ns. Three of them have been used in the Document Under- standing Conference (DUC) 2004, a large -scale summarization evaluation sponsored by NIST. 
33;2015;Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems;TLDR: Proposes a neural natural language generator that jointly optimises sentence planning and surface realization, outperforming other systems on human eval.;https://arxiv.org/pdf/1508.01745.pdf;9; Question Answering/Reading Comprehension;Natural language generation (NLG) is a critical component of spoken dialogue and it has a significant impact both on usabil- ity and perceived quality. Most NLG sys- tems in common use employ rules and heuristics and tend to generate rigid and stylised responses without the natural vari- ation of human language. They are also not easily scaled to systems covering mul- tiple domains and languages. This pa- per presents a statistical language gener- ator based on a semantically controlled Long Short-term Memory (LSTM) struc- ture. The LSTM generator can learn from unaligned data by jointly optimising sen- tence planning and surface realisation us- ing a simple cross entropy training crite- rion, and language variation can be eas- ily achieved by sampling from output can- didates. With fewer heuristics, an objec- tive evaluation in two differing test do- mains showed the proposed method im- proved performance compared to previ- ous methods. Human judges scored the LSTM system higher on informativeness and naturalness and overall preferred it to the other systems. 
34;2016;Pointing the Unknown Words;TLDR: Proposes a copy-mechanism for allowing MT systems to more effectively copy words from a source context sequence.;https://arxiv.org/pdf/1603.08148.pdf;9; Question Answering/Reading Comprehension;ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It includes measures to auto- matically determine the quality of a summary by comparing it to other (ideal) summaries created by humans. The measures count the number of over- lapping units such as n-gram, word sequences, and word pairs between the computer-generated sum- mary to be evaluated and the ideal summaries cre- ated by humans. This paper introduces four different ROUGE measures: ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S included in the ROUGE summariza- tion evaluation package and their evaluatio ns. Three of them have been used in the Document Under- standing Conference (DUC) 2004, a large -scale summarization evaluation sponsored by NIST. 
35;2017;Get To The Point: Summarization with Pointer-Generator Networks;TLDR: This work offers an elegant soft copy mechanism, that drastically outperforms the SOTA on abstractive summarization.;https://arxiv.org/pdf/1704.04368.pdf;10; Natural Language Generation/Summarization;Neural sequence-to-sequence models have provided a viable new approach for ab- stractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the origi- nal text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we pro- pose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate repro- duction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail sum- marization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points. 
36;2011;Data-drive Response Generation in Social Media;TLDR: Proposes using phrase-based statistical machine translation methods to the problem of response generation.;http://dl.acm.org/citation.cfm?id=2145500;10; Natural Language Generation/Summarization;Human evaluations of machine translation are extensive but expensive. Human eval- uations can take months to finish and in- volve human labor that can not be reused. We propose a method of automatic ma- chine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evalu- ation, and that has little marginal cost per run. We present this method as an auto- mated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations 
37;2015;Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems;TLDR: Proposes a neural natural language generator that jointly optimises sentence planning and surface realization, outperforming other systems on human eval.;https://arxiv.org/pdf/1508.01745.pdf;10; Natural Language Generation/Summarization;Natural language generation (NLG) is a critical component of spoken dialogue and it has a significant impact both on usabil- ity and perceived quality. Most NLG sys- tems in common use employ rules and heuristics and tend to generate rigid and stylised responses without the natural vari- ation of human language. They are also not easily scaled to systems covering mul- tiple domains and languages. This pa- per presents a statistical language gener- ator based on a semantically controlled Long Short-term Memory (LSTM) struc- ture. The LSTM generator can learn from unaligned data by jointly optimising sen- tence planning and surface realisation us- ing a simple cross entropy training crite- rion, and language variation can be eas- ily achieved by sampling from output can- didates. With fewer heuristics, an objec- tive evaluation in two differing test do- mains showed the proposed method im- proved performance compared to previ- ous methods. Human judges scored the LSTM system higher on informativeness and naturalness and overall preferred it to the other systems. 
38;2016;How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation;TLDR: Important work demonstrating that existing automatic metrics used for dialogue woefully do not correlate well with human judgment.;https://arxiv.org/pdf/1603.08023.pdf;10; Natural Language Generation/Summarization;We investigate evaluation metrics for dialogue response generation systems where supervised labels, such as task completion, are not avail- able. Recent works in response generation have adopted metrics from machine transla- tion to compare a model’s generated response to a single target response. We show that these metrics correlate very weakly with hu- man judgements in the non-technical Twitter domain, and not at all in the technical Ubuntu domain. We provide quantitative and quali- tative results highlighting specific weaknesses in existing metrics, and provide recommenda- tions for future development of better auto- matic evaluation metrics for dialogue systems. 
39;2016;A Network-based End-to-End Trainable Task-oriented Dialogue System;TLDR: Proposes a neat architecture for decomposing a dialogue system into a number of individually-trained neural network components.;https://arxiv.org/pdf/1604.04562.pdf;11; Dialogue Systems;Teaching machines to accomplish tasks by conversing naturally with humans is challenging. Currently, developing task- oriented dialogue systems requires creating multiple components and typically this in- volves either a large amount of handcraft- ing, or acquiring costly labelled datasets to solve a statistical learning problem for each component. In this work we intro- duce a neural network-based text-in, text- out end-to-end trainable goal-oriented di- alogue system along with a new way of collecting dialogue data based on a novel pipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue sys- tems easily and without making too many assumptions about the task at hand. The results show that the model can converse with human subjects naturally whilst help- ing them to accomplish tasks in a restaurant search domain. 
40;2016;A Diversity-Promoting Objective Function for Neural Conversation Models;TLDR: Introduces a maximum mutual information objective function for training dialogue systems.;https://arxiv.org/pdf/1510.03055.pdf;11; Dialogue Systems;Sequence-to-sequence neural network mod- els for generation of conversational responses tend to generate safe, commonplace responses (e.g., I don’t know) regardless of the input. We suggest that the traditional objective func- tion, i.e., the likelihood of output (response) given input (message) is unsuited to response generation tasks. Instead we propose using Maximum Mutual Information (MMI) as the objective function in neural models. Experi- mental results demonstrate that the proposed MMI models produce more diverse, interest- ing, and appropriate responses, yielding sub- stantive gains in BLEU scores on two conver- sational datasets and in human evaluations. 
41;2016;The Dialogue State Tracking Challenge Series: A Review;TLDR: A nice overview of the dialogue state tracking challenges for dialogue systems.;https://pdfs.semanticscholar.org/4ba3/39bd571585fadb1fb1d14ef902b6784f574f.pdf;11; Dialogue Systems;"In a spoken dialog system, dialog state tracking refers to the task of correctly inferring the state of the conversation – such as the user’s goal – given all of the dialog history up to that turn. Dialog state tracking is crucial to the success of a dialog system, yet until recently there were no common resources, hampering progress. The Dialog State Tracking Challenge series of 3 tasks introduced the first shared testbed and evaluation metrics for dialog state tracking, and has underpinned three key advances in dialog state tracking: the move from generative to discriminative models; the adoption of discriminative sequential techniques; and the incorporation of the speech recognition results directly into the dialog state tracker. This paper reviews this research area, covering both the challenge tasks themselves and summarizing the work they have enabled."
42;2017;A Copy-Augmented Sequence-to-Sequence Architecture Gives Good Performance on Task-Oriented Dialogue;TLDR: Shows that simple sequence-to-sequence architectures with a copy mechanism can perform competitively on existing task-oriented dialogue datasets.;https://arxiv.org/pdf/1701.04024.pdf;11; Dialogue Systems;Task-oriented dialogue focuses on con- versational agents that participate in dia- logues with user goals on domain-specific topics. In contrast to chatbots, which sim- ply seek to sustain open-ended meaning- ful discourse, existing task-oriented agents usually explicitly model user intent and belief states. This paper examines bypass- ing such an explicit representation by de- pending on a latent neural embedding of state and learning selective attention to di- alogue history together with copying to in- corporate relevant prior context. We com- plement recent work by showing the effec- tiveness of simple sequence-to-sequence neural architectures with a copy mecha- nism. Our model outperforms more com- plex memory-augmented models by 7% in per-response generation and is on par with the current state-of-the-art on DSTC2, a real-world task-oriented dialogue dataset 
43;2017;Key-Value Retrieval Networks for Task-Oriented Dialogue;TLDR: Introduces a new multidomain dataset for task-oriented dataset as well as an architecture for softly incorporating information from structured knowledge bases into dialogue systems.;https://arxiv.org/pdf/1705.05414.pdf;11; Dialogue Systems;Neural task-oriented dialogue systems of- ten struggle to smoothly interface with a knowledge base. In this work, we seek to address this problem by proposing a new neural dialogue agent that is able to effec- tively sustain grounded, multi-domain dis- course through a novel key-value retrieval mechanism. The model is end-to-end dif- ferentiable and does not need to explicitly model dialogue state or belief trackers. We also release a new dataset of 3,031 dia- logues that are grounded through underly- ing knowledge bases and span three dis- tinct tasks in the in-car personal assistant space: calendar scheduling, weather infor- mation retrieval, and point-of-interest nav- igation. Our architecture is simultaneously trained on data from all domains and sig- nificantly outperforms a competitive rule- based system and other existing neural di- alogue architectures on the provided do- mains according to both automatic and hu- man evaluation metrics. 
44;2017;Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings;TLDR: Introduces a new collaborative dialogue dataset, as well as an architecture for representing structured knowledge via knowledge graph embeddings.;https://arxiv.org/pdf/1704.07130.pdf;11; Dialogue Systems;We study a symmetric collaborative dia- logue setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this set- ting poses new challenges for existing di- alogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both struc- tured knowledge and unstructured lan- guage, we propose a neural model with dy- namic knowledge graph embeddings that evolve as the dialogue progresses. Au- tomatic and human evaluations show that our model is both more effective at achiev- ing the goal and more human-like than baseline neural and rule-based models. 
45;2017;Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning;TLDR: Introduces a hybrid dialogue architecture that can be jointly trained via supervised learning as well as reinforcement learning and combines neural network techniques with fine-grained rule-based approaches.;https://arxiv.org/pdf/1702.03274.pdf;11; Dialogue Systems;"End-to-end learning of recurrent neural networks (RNNs) is an attractive solu- tion for dialog systems; however, cur- rent techniques are data-intensive and re- quire thousands of dialogs to learn sim- ple behaviors. We introduce Hybrid Code Networks (HCNs), which combine an RNN with domain-specific knowledge encoded as software and system action templates. Compared to existing end-to- end approaches, HCNs considerably re- duce the amount of training data required, while retaining the key benefit of inferring a latent representation of dialog state. In addition, HCNs can be optimized with su- pervised learning, reinforcement learning, or a mixture of both. HCNs attain state- of-the-art performance on the bAbI dialog dataset (Bordes and Weston, 2016), and outperform two commercially deployed customer-facing dialog systems. "
46;1971;Procedures as a Representation for Data in a Computer Program for Understanding Natural Language;TLDR: One of the seminal papers in computer science, introducing SHRDLU an early system for computers understanding human language commands.;http://hci.stanford.edu/~winograd/shrdlu/AITR-235.pdf;11; Dialogue Systems;
47;2016;Learning language games through interaction;TLDR: Introduces a novel setting for interacting with computers to accomplish a task where only natural language can be used to communicate with the system!;https://arxiv.org/pdf/1606.02447.pdf;11; Dialogue Systems;We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36% (LP/LR F1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the- art. This result has potential uses beyond establish- ing a strong lower bound on the maximum possi- ble accuracy of unlexicalized models: an unlexical- ized PCFG is much more compact, easier to repli- cate, and easier to interpret than more complex lex- ical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic com- plexity, and easier to optimize. 
48;2017;Naturalizing a programming language via interactive learning;TLDR: Very cool work allowing a community of workers to iteratively naturalize a language starting with a core set of commands in an interactive task.;https://arxiv.org/pdf/1704.06956.pdf;11; Dialogue Systems;Our goal is to create a convenient natu- ral language interface for performing well- specified but complex actions such as ana- lyzing data, manipulating text, and query- ing databases. However, existing natu- ral language interfaces for such tasks are quite primitive compared to the power one wields with a programming language. To bridge this gap, we start with a core pro- gramming language and allow users to “naturalize” the core language incremen- tally by defining alternative, more natural syntax and increasingly complex concepts in terms of compositions of simpler ones. In a voxel world, we show that a com- munity of users can simultaneously teach a common system a diverse language and use it to build hundreds of complex voxel structures. Over the course of three days, these users went from using only the core language to using the naturalized language in 85.9% of the last 10K utterances. 
49;1996;An Empirical Study of Smoothing Techniques for Language Modelling;TLDR: Performs an extensive survey of smoothing techniques in traditional language modelling systems.;https://aclweb.org/anthology/P96-1041;12; Interactive Learning;We present an extensive empirical com- parison of several smoothing techniques in the domain of language modeling, includ- ing those described by Jelinek and Mer- cer (1980), Katz (1987), and Church and Gale (1991). We investigate for the first time how factors such as training data size, corpus (e.g., Brown versus Wall Street Journal), and n-gram order (bigram versus trigram) affect the relative performance of these methods, which we measure through the cross-entropy of test data. In addition, we introduce two novel smoothing tech- niques, one a variation of Jelinek-Mercer smoothing and one a very simple linear in- terpolation technique, both of which out- perform existing methods.
50;2003;A Neural Probabilistic Language Model;TLDR: A seminal work in deep learning for NLP, introducing one of the earliest effective models for neural network-based language modelling.;http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf;12; Interactive Learning;A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.
51;2014;One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling;TLDR: Introduces the Google One Billion Word language modelling benchmark.;https://arxiv.org/pdf/1312.3005.pdf;12; Interactive Learning;"We propose a new benchmark corpus to be used for measuring progress in statistical lan- guage modeling. With almost one billion words of training data, we hope this bench- mark will be useful to quickly evaluate novel language modeling techniques, and to com- pare their contribution when combined with other advanced techniques. We show perfor- mance of several well-known types of lan- guage models, with the best results achieved with a recurrent neural network based lan- guage model. The baseline unpruned Kneser- Ney 5-gram model achieves perplexity 67.6. A combination of techniques leads to 35% reduction in perplexity, or 10% reduction in cross-entropy (bits), over that baseline. The benchmark is available as a code.google.com project; besides the scripts needed to rebuild the training/held-out data, it also makes available log-probability values for each word in each of ten held-out data sets, for each of the baseline n-gram models."
52;2015;Character-Aware Neural Language Models;TLDR: Proposes a language model using convolutional neural networks that can employ character-level information, performing on-par with word-level LSTM systems.;https://arxiv.org/pdf/1508.06615.pdf;13; Language Modelling;We describe a simple neural language model that re- lies only on character-level inputs. Predictions are still made at the word-level. Our model employs a con- volutional neural network (CNN) and a highway net- work over characters, whose output is given to a long short-term memory (LSTM) recurrent neural net- work language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model out- performs word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for lan- guage modeling. Analysis of word representations ob- tained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information. 
53;2016;Exploring the Limits of Language Modeling;TLDR: Introduces a mega language model system using deep learning that uses a variety of techniques and significantly performs the SOTA on the One Billion Words Benchmark.;https://arxiv.org/pdf/1602.02410.pdf;13; Language Modelling;In this work we explore recent advances in Re- current Neural Networks for large scale Lan- guage Modeling, a task central to language un- derstanding. We extend current models to deal with two key challenges present in this task: cor- pora and vocabulary sizes, and complex, long term structure of language. We perform an ex- haustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Bench- mark. Our best single model significantly im- proves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of param- eters by a factor of 20), while an ensemble of models sets a new record by improving perplex- ity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon. 
54;2018;Deep contextualized word representations;TLDR: This paper introduces ELMO, a super powerful collection of word embeddings learned from the intermediate representations of a deep bidirectional LSTM language model. Achieved SOTA on 6 diverse NLP tasks.;https://arxiv.org/pdf/1802.05365.pdf;13; Language Modelling;We introduce a new type of deep contextual- ized word representation that models both (1) complex characteristics of word use (e.g., syn- tax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned func- tions of the internal states of a deep bidirec- tional language model (biLM), which is pre- trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, tex- tual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals. 
55;2018;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding;TLDR: One of the most important papers of 2018, introducing BERT a powerful architecture pretrained using language modelling which is then effectively transferred to other domain-specific tasks.;https://arxiv.org/pdf/1810.04805.pdf;13; Language Modelling;The problem of rare and unknown words is an important issue that can potentially effect the performance of many NLP sys- tems, including traditional count-based and deep learning models. We propose a novel way to deal with the rare and unseen words for the neural network models us- ing attention. Our model uses two softmax layers in order to predict the next word in conditional language models: one predicts the location of a word in the source sen- tence, and the other predicts a word in the shortlist vocabulary. At each timestep, the decision of which softmax layer to use is adaptively made by an MLP which is con- ditioned on the context. We motivate this work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the envi- ronment when the name of an object is not known. Using our proposed model, we ob- serve improvements on two tasks, neural machine translation on the Europarl En- glish to French parallel corpora and text summarization on the Gigaword dataset. 
56;2019;XLNet: Generalized Autoregressive Pretraining for Language Understanding;TLDR: Generalized autoregressive pretraining method that improves upon BERT by maximizing the expected likelihood over all permutations of the factorization order.;https://arxiv.org/pdf/1906.08237.pdf;13; Language Modelling;With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining ap- proaches based on autoregressive language modeling. However, relying on corrupt- ing the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, XLNet outperforms BERT on 20 tasks, often by a large margin, and achieves state-of-the-art results on 18 tasks including question answering, natural language inference, sentiment analysis, and document ranking 
58;2000;Maximum Entropy Markov Models for Information Extraction and Segmentation;TLDR: Introduces Markov Entropy Markov models for information extraction, a commonly used ML technique in classical NLP.;https://www.seas.upenn.edu/~strctlrn/bib/PDF/memm-icml2000.pdf;13; Language Modelling;Hidden Markov models (HMMs) are a powerful probabilistic tool for modeling sequential data, and have been applied with success to many text-related tasks, such as part-of-speech tagging, text segmentation and information extraction. In these cases, the observations are usually mod- eled as multinomial distributions over a discrete vocabulary, and the HMM parameters are set to maximize the likelihood of the observations. This paper presents a new Markovian sequence model, closely related to HMMs, that allows ob- servations to be represented as arbitrary overlap- ping features (such as word, capitalization, for- matting, part-of-speech), and defines the condi- tional probability of state sequences given ob- servation sequences. It does this by using the maximum entropy framework to fit a set of expo- nential models that represent the probability of a state given an observation and the previous state. We present positive experimental results on the segmentation of FAQ’s. 
59;2010;From Frequency to Meaning: Vector Space Models of Semantics;TLDR: A wonderful survey of existing vector space models for learning semantics in text.;https://arxiv.org/pdf/1003.1141.pdf;13; Language Modelling;Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term–document, word–context, and pair–pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field 
60;2012;An Introduction to Conditional Random Fields;TLDR: A nice, in-depth overview of conditional random fields, a commonly-used sequence-labelling model.;http://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf;13; Language Modelling;Many tasks involve predicting a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling. They combine the ability of graphical models to compactly model multivariate data with the ability of classifica- tion methods to perform prediction using large sets of input features. This survey describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in many areas, including natural language processing, computer vision, and bioinformatics. We describe methods for inference and parame- ter estimation for CRFs, including practical issues for implementing large-scale CRFs. We do not assume previous knowledge of graphical modeling, so this survey is intended to be useful to practitioners in a wide variety of fields. 
61;2014;Glove: Global vectors for word representation;TLDR: Introduces Glove word embeddings, one of the most commonly used pretrained word embedding techniques across all flavors of NLP models;https://nlp.stanford.edu/pubs/glove.pdf;14; Miscellanea;Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arith- metic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global log- bilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word co- occurrence matrix, rather than on the en- tire sparse matrix or on individual context windows in a large corpus. The model pro- duces a vector space with meaningful sub- structure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on simi- larity tasks and named entity recognition. 
62;2014;Don‚Äôt count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors;TLDR: Important paper demonstrating that context-predicting distributional semantics approaches outperform count-based techniques.;http://www.aclweb.org/anthology/P14-1023;14; Miscellanea;Context-predicting models (more com- monly known as embeddings or neural language models) are the new kids on the distributional semantics block. Despite the buzz surrounding these models, the litera- ture is still lacking a systematic compari- son of the predictive models with classic, count-vector-based distributional semantic approaches. In this paper, we perform such an extensive evaluation, on a wide range of lexical semantics tasks and across many parameter settings. The results, to our own surprise, show that the buzz is fully justified, as the context-predicting models obtain a thorough and resounding victory against their count-based counter- parts. 
63;2015;Improving Distributional Similarity with Lessons Learned From Word Embeddings;TLDR: Demonstrates that traditional distributional semantics techniques can be enhanced with certain design choices and hyperparameter optimizations that make their performance rival that of neural network-based embedding methods.;https://www.aclweb.org/anthology/Q15-1016;14; Miscellanea;Recent trends suggest that neural- network-inspired word embedding models outperform traditional count-based distri- butional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter op- timizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others. 
64;2018;Universal Language Model Fine-tuning for Text Classification;TLDR: Provides a smorgasbord of nice techniques for finetuning language models that can be effectively transferred to text classification tasks.;https://arxiv.org/pdf/1801.06146.pdf;14; Miscellanea;Inductive transfer learning has greatly im- pacted computer vision, but existing ap- proaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective trans- fer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outper- forms the state-of-the-art on six text clas- sification tasks, reducing the error by 18- 24% on the majority of datasets. Further- more, with only 100 labeled examples, it matches the performance of training from scratch on 100_ more data. We open- source our pretrained models and code 
65;2019;Analogies Explained: Towards Understanding Word Embeddings;TLDR: Very nice work providing a mathematical formalism for understanding some of the paraphrasing properties of modern word embeddings.;https://arxiv.org/pdf/1901.09813.pdf;14; Miscellanea;Word embeddings generated by neural network methods such as word2vec (W2V) are well known to exhibit seemingly linear behaviour, e.g. the embeddings of analogy “woman is to queen as man is to king” approximately describe a paral- lelogram. This property is particularly intriguing since the embeddings are not trained to achieve it. Several explanations have been proposed, but each introduces assumptions that do not hold in practice. We derive a probabilistically grounded definition of paraphrasing that we re-interpret as word transformation, a mathematical descrip- tion of “wx is to wy”. From these concepts we prove existence of linear relationships between W2V-type embeddings that underlie the analogi- cal phenomenon, identifying explicit error terms. 